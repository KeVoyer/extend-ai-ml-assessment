{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection in wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "from Model import MyNet\n",
    "import torch.optim as optim\n",
    "import torch.nn\n",
    "from pathlib import Path\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'un défaut dans le bois n'est pas fonction de la grandeur on peut augmenter notre dataset en sélectionnant des parties aléatoires (RandomCrop). le choix de 224x224 est arbitraire. \n",
    "\n",
    "Dans le jeu de données toutes les images sont orientées dans la même direction (le grain du bois). Ce ne serait surement pas toujours le cas donc il vaut mieux ajouter une rotation dans les images ($\\pm 180 \\degree$). Cela permet d'éviter loverfitting sur les quelques défauts présents dans le jeu de données. On ne voudrait pas que le modele apprenne à repérer seulement certains types de fissure parce que celles-ci sont dans la bonne orientation\n",
    "\n",
    "Dans le problème actuel la couleur du bois est peu (pas) importante. On peut donc convertir nos images en noir et blanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(pictures_size), \n",
    "    transforms.RandomRotation(180), \n",
    "     transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     \n",
    " ])\n",
    "\n",
    "dataset = datasets.ImageFolder(\"data\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=7, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour résoudre le problème de façon non supervisé j'ai cherché, et trouvé, l'article suivant : https://arxiv.org/pdf/2007.09990.pdf\n",
    "\n",
    "Ils ont rendu le code disponible sur github : https://github.com/kanezaki/pytorch-unsupervised-segmentation-tip\n",
    "\n",
    "J'ai donc utilisé leur modèle ainsi que la \"costom\" loss qui permet de pénaliser en fonction de la distance des pixel ainsi que de la variation entre la couleur (niveau de gris)\n",
    "\n",
    "On peut ajuster la sensibilité en modition les \"stepsize_con\" et \"stepsize_sim\" \n",
    "\n",
    "On pourrait aussi utiliser l'option \"scribble\" en entourant les anomalies (ca devient alors un probleme (semi) supervisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 100\n",
    "max_nb_class = 5\n",
    "\n",
    "visualize = False\n",
    "scribble =False\n",
    "\n",
    "stepsize_scr = 1\n",
    "stepsize_con = 1\n",
    "stepsize_sim = 3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# MyNet(number_of_channel, maximum_number_of_classes, number_of_convolution + 2)\n",
    "model = MyNet(1, max_nb_class, 2)\n",
    "\n",
    "model.cuda() if use_cuda else model.cpu()\n",
    "model.train()\n",
    "# similarity loss definition\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scribble loss definition\n",
    "loss_fn_scr = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# continuity loss definition\n",
    "loss_hpy = torch.nn.L1Loss(reduction=\"mean\")\n",
    "loss_hpz = torch.nn.L1Loss(reduction=\"mean\")\n",
    "\n",
    "HPy_target = torch.zeros(pictures_size - 1, pictures_size, max_nb_class)\n",
    "HPz_target = torch.zeros(pictures_size, pictures_size - 1, max_nb_class)\n",
    "\n",
    "if use_cuda:\n",
    "    HPy_target = HPy_target.cuda()\n",
    "    HPz_target = HPz_target.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5)\n",
    "label_colours = np.random.randint(255, size=(max_nb_class,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 100 | label num : 5 | loss : 4.219082832336426\n",
      "1 / 100 | label num : 5 | loss : 3.307284116744995\n",
      "2 / 100 | label num : 5 | loss : 2.782369375228882\n",
      "3 / 100 | label num : 5 | loss : 1.8548731803894043\n",
      "4 / 100 | label num : 5 | loss : 2.4779086112976074\n",
      "5 / 100 | label num : 5 | loss : 1.090612769126892\n",
      "6 / 100 | label num : 5 | loss : 0.7670782804489136\n",
      "7 / 100 | label num : 5 | loss : 2.2937545776367188\n",
      "8 / 100 | label num : 5 | loss : 0.43182921409606934\n",
      "9 / 100 | label num : 5 | loss : 0.40151649713516235\n",
      "10 / 100 | label num : 5 | loss : 0.5372830033302307\n",
      "11 / 100 | label num : 5 | loss : 0.35117754340171814\n",
      "12 / 100 | label num : 4 | loss : 1.2156084775924683\n",
      "13 / 100 | label num : 4 | loss : 0.2267618477344513\n",
      "14 / 100 | label num : 4 | loss : 0.3121795952320099\n",
      "15 / 100 | label num : 4 | loss : 0.2525736689567566\n",
      "16 / 100 | label num : 4 | loss : 0.2750709652900696\n",
      "17 / 100 | label num : 4 | loss : 0.22470223903656006\n",
      "18 / 100 | label num : 4 | loss : 0.20376259088516235\n",
      "19 / 100 | label num : 4 | loss : 0.18229621648788452\n",
      "20 / 100 | label num : 4 | loss : 0.18658089637756348\n",
      "21 / 100 | label num : 4 | loss : 0.17169703543186188\n",
      "22 / 100 | label num : 4 | loss : 0.1802160143852234\n",
      "23 / 100 | label num : 4 | loss : 0.16500891745090485\n",
      "24 / 100 | label num : 4 | loss : 0.14410018920898438\n",
      "25 / 100 | label num : 4 | loss : 0.15961886942386627\n",
      "26 / 100 | label num : 4 | loss : 0.16005617380142212\n",
      "27 / 100 | label num : 3 | loss : 0.10229586064815521\n",
      "28 / 100 | label num : 4 | loss : 0.12271564453840256\n",
      "29 / 100 | label num : 3 | loss : 0.11560339480638504\n",
      "30 / 100 | label num : 3 | loss : 0.09956097602844238\n",
      "31 / 100 | label num : 3 | loss : 0.12002439796924591\n",
      "32 / 100 | label num : 2 | loss : 0.08873842656612396\n",
      "33 / 100 | label num : 2 | loss : 0.10058325529098511\n",
      "34 / 100 | label num : 2 | loss : 0.10744751989841461\n",
      "35 / 100 | label num : 2 | loss : 0.10724080353975296\n",
      "36 / 100 | label num : 2 | loss : 0.11652591079473495\n",
      "37 / 100 | label num : 2 | loss : 0.09482473134994507\n",
      "38 / 100 | label num : 2 | loss : 0.094511479139328\n",
      "39 / 100 | label num : 2 | loss : 0.11787203699350357\n",
      "40 / 100 | label num : 2 | loss : 0.09221024811267853\n",
      "41 / 100 | label num : 2 | loss : 0.08872982859611511\n",
      "42 / 100 | label num : 2 | loss : 0.10319732129573822\n",
      "43 / 100 | label num : 2 | loss : 0.028680438175797462\n",
      "44 / 100 | label num : 2 | loss : 0.09135954827070236\n",
      "45 / 100 | label num : 2 | loss : 0.08206446468830109\n",
      "46 / 100 | label num : 2 | loss : 0.07652858644723892\n",
      "47 / 100 | label num : 2 | loss : 0.09265105426311493\n",
      "48 / 100 | label num : 2 | loss : 0.07811226695775986\n",
      "49 / 100 | label num : 2 | loss : 0.0842655599117279\n",
      "50 / 100 | label num : 2 | loss : 0.09385977685451508\n",
      "51 / 100 | label num : 2 | loss : 0.08309275656938553\n",
      "52 / 100 | label num : 2 | loss : 0.0626857578754425\n",
      "53 / 100 | label num : 2 | loss : 0.05301735922694206\n",
      "54 / 100 | label num : 2 | loss : 0.08500451594591141\n",
      "55 / 100 | label num : 2 | loss : 0.07657693326473236\n",
      "56 / 100 | label num : 2 | loss : 0.08375485986471176\n",
      "57 / 100 | label num : 2 | loss : 0.09512587636709213\n",
      "58 / 100 | label num : 2 | loss : 0.08247412741184235\n",
      "59 / 100 | label num : 2 | loss : 0.06827723979949951\n",
      "60 / 100 | label num : 2 | loss : 0.06525823473930359\n",
      "61 / 100 | label num : 2 | loss : 0.08849453926086426\n",
      "62 / 100 | label num : 2 | loss : 0.0845099687576294\n",
      "63 / 100 | label num : 2 | loss : 0.04350433498620987\n",
      "64 / 100 | label num : 1 | loss : 0.010295430198311806\n",
      "65 / 100 | label num : 2 | loss : 0.09027394652366638\n",
      "66 / 100 | label num : 2 | loss : 0.08239982277154922\n",
      "67 / 100 | label num : 2 | loss : 0.07835952192544937\n",
      "68 / 100 | label num : 2 | loss : 0.08718058466911316\n",
      "69 / 100 | label num : 2 | loss : 0.07966163009405136\n",
      "70 / 100 | label num : 2 | loss : 0.07896644622087479\n",
      "71 / 100 | label num : 2 | loss : 0.10036180913448334\n",
      "72 / 100 | label num : 2 | loss : 0.07950245589017868\n",
      "73 / 100 | label num : 2 | loss : 0.08663724362850189\n",
      "74 / 100 | label num : 2 | loss : 0.08248187601566315\n",
      "75 / 100 | label num : 2 | loss : 0.09235672652721405\n",
      "76 / 100 | label num : 2 | loss : 0.08144795894622803\n",
      "77 / 100 | label num : 2 | loss : 0.08704254776239395\n",
      "78 / 100 | label num : 2 | loss : 0.07765065878629684\n",
      "79 / 100 | label num : 2 | loss : 0.07284272462129593\n",
      "80 / 100 | label num : 2 | loss : 0.07506398856639862\n",
      "81 / 100 | label num : 2 | loss : 0.08501709252595901\n",
      "82 / 100 | label num : 2 | loss : 0.06342080235481262\n",
      "83 / 100 | label num : 2 | loss : 0.08170323073863983\n",
      "84 / 100 | label num : 2 | loss : 0.07735155522823334\n",
      "85 / 100 | label num : 2 | loss : 0.06846556067466736\n",
      "86 / 100 | label num : 2 | loss : 0.08210425823926926\n",
      "87 / 100 | label num : 2 | loss : 0.07329634577035904\n",
      "88 / 100 | label num : 2 | loss : 0.08379770815372467\n",
      "89 / 100 | label num : 2 | loss : 0.0821543037891388\n",
      "90 / 100 | label num : 2 | loss : 0.08121898025274277\n",
      "91 / 100 | label num : 2 | loss : 0.08013123273849487\n",
      "92 / 100 | label num : 2 | loss : 0.08067601919174194\n",
      "93 / 100 | label num : 2 | loss : 0.07405831664800644\n",
      "94 / 100 | label num : 2 | loss : 0.059322893619537354\n",
      "95 / 100 | label num : 2 | loss : 0.03452567756175995\n",
      "96 / 100 | label num : 2 | loss : 0.04181332141160965\n",
      "97 / 100 | label num : 2 | loss : 0.09336037188768387\n",
      "98 / 100 | label num : 2 | loss : 0.0779983401298523\n",
      "99 / 100 | label num : 2 | loss : 0.10006808489561081\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nepoch):\n",
    "    for data, _ in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)[0]\n",
    "\n",
    "        output = output.permute(1, 2, 0).contiguous().view(-1, max_nb_class)\n",
    "        outputHP = output.reshape((pictures_size, pictures_size, max_nb_class))\n",
    "\n",
    "        HPy = outputHP[1:, :, :] - outputHP[0:-1, :, :]\n",
    "        HPz = outputHP[:, 1:, :] - outputHP[:, 0:-1, :]\n",
    "        lhpy = loss_hpy(HPy, HPy_target)\n",
    "        lhpz = loss_hpz(HPz, HPz_target)\n",
    "\n",
    "        ignore, target = torch.max(output, 1)\n",
    "\n",
    "        im_target = target.data.cpu().numpy()\n",
    "        nLabels = len(np.unique(im_target))\n",
    "        if visualize:\n",
    "            im_target_rgb = np.array(\n",
    "                [label_colours[c % max_nb_class] for c in im_target]\n",
    "            )\n",
    "\n",
    "            im_target_rgb = im_target_rgb.reshape((pictures_size, pictures_size, 3)).astype(\n",
    "                np.uint8\n",
    "            )\n",
    "            cv2.imshow(\"output\", im_target_rgb)\n",
    "            cv2.waitKey(100)\n",
    "\n",
    "        # loss\n",
    "        if scribble:\n",
    "            loss = (\n",
    "                stepsize_sim * loss_fn(output[inds_sim], target[inds_sim])\n",
    "                + stepsize_scr\n",
    "                * loss_fn_scr(output[inds_scr], target_scr[inds_scr])\n",
    "                + stepsize_con * (lhpy + lhpz)\n",
    "            )\n",
    "        else:\n",
    "            loss = stepsize_sim * loss_fn(output, target) + stepsize_con * (\n",
    "                lhpy + lhpz\n",
    "            )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "    print(\n",
    "            f\"{epoch} / {nepoch} | label num : {nLabels} | loss : {loss.item()}\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mymodel.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "  (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): ModuleList(\n",
       "    (0): Conv2d(5, 5, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "  )\n",
       "  (bn2): ModuleList(\n",
       "    (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Conv2d(5, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNet(1, max_nb_class, 2)\n",
    "model.load_state_dict(torch.load('mymodel.save'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr = transforms.Compose([\n",
    "     transforms.Grayscale(),\n",
    "     transforms.ToTensor()]\n",
    " )\n",
    "\n",
    "paths = glob.glob('data/train/*.jpg')\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    data = tr(img).unsqueeze(0)\n",
    "\n",
    "    output = model(data)[0]\n",
    "    output = output.permute(1, 2, 0).contiguous().view(-1, max_nb_class)\n",
    "    ignore, target = torch.max(output, 1)\n",
    "   \n",
    "    im_target = target.data.cpu().numpy()\n",
    "    im_target_rgb = np.array([label_colours[c % max_nb_class] for c in im_target])\n",
    "    im_target_rgb = im_target_rgb.reshape((img.size[1], img.size[0], 3)).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    Path(\"results\").mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(f\"results/{path.rsplit('/',1)[1]}\", im_target_rgb)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb86d2497654d5e221ed42f8a37cadbea5e752644e70ad57e49e6b60205c9146"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
